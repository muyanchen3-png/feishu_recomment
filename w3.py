# workflow_system.py

from abc import ABC, abstractmethod
import json
import os
import requests
from bs4 import BeautifulSoup
from typing import Dict, Any, List
from enum import Enum
from dataclasses import dataclass
from datetime import datetime
import threading
import random
import time
import pickle
from dotenv import load_dotenv  # æ–°å¢ï¼šç¯å¢ƒå˜é‡ç®¡ç†

# ========== åŠ è½½ç¯å¢ƒå˜é‡ ==========
load_dotenv()

# ================== æŠ½è±¡æ¥å£å®šä¹‰ ==================
class LLM_INTERFACE(ABC):
    @abstractmethod
    def send_message(self, prompt: str, json_flag: bool = False) -> str:
        pass


# ================== èŠ‚ç‚¹é…ç½®ç±» ==================
@dataclass
class NodeConfig:
    node_id: int
    node_type: str
    node_name: str
    input_map: Dict[str, str]
    choice_map: Dict[str, str]
    attrs: Dict[str, Any]


# ================== Selenium ç™»å½•åŠ©æ‰‹ ==================
class WeiboLoginHelper:
    """
    ä½¿ç”¨ Selenium è‡ªåŠ¨ç™»å½•å¾®åšï¼Œè·å–å¹¶ä¿å­˜ Cookie
    """

    def __init__(self, username: str, password: str, cookie_path: str = "weibo_cookie.pkl"):
        self.username = username
        self.password = password
        self.cookie_path = cookie_path
        self.driver = None

    def create_driver(self):
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.chrome.service import Service

        options = Options()
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--disable-infobars")
        options.add_argument("--start-maximized")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--remote-allow-origins=*")
        # å¯é€‰ï¼šæ— å¤´æ¨¡å¼ï¼ˆéƒ¨ç½²æ—¶å¯ç”¨ï¼‰
        # options.add_argument('--headless')

        # é˜²æ­¢è¢«è¯†åˆ«ä¸ºè‡ªåŠ¨åŒ–å·¥å…·
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)

        driver = webdriver.Chrome(options=options)
        driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": "Object.defineProperty(navigator, 'webdriver', {get: () => false});"
        })
        return driver

    def login(self) -> str:
        try:
            self.driver = self.create_driver()
            self.driver.get("https://weibo.com/login.php")
            print("ğŸŒ æ‰“å¼€å¾®åšç™»å½•é¡µ...")

            time.sleep(3)

            # è¾“å…¥è´¦å·å¯†ç 
            print("ğŸ“ æ­£åœ¨è¾“å…¥è´¦å·å¯†ç ...")
            self.driver.find_element("name", "username").send_keys(self.username)
            self.driver.find_element("name", "password").send_keys(self.password)
            login_btn = self.driver.find_element("xpath", '//div[@class="info_list login_btn"]/a')
            login_btn.click()

            time.sleep(5)

            # ç­‰å¾…ç™»å½•å®Œæˆï¼ˆå¯äººå·¥å¤„ç†æ»‘å—éªŒè¯ç ï¼‰
            while True:
                current_url = self.driver.current_url
                if "myprofile" in current_url or "weibo.com/u" in current_url or "home" in current_url:
                    print("âœ… ç™»å½•æˆåŠŸï¼")
                    break
                else:
                    print("â³ è¯·æ‰‹åŠ¨å®ŒæˆéªŒè¯ç æˆ–æ‰«ç ç™»å½•...")
                    time.sleep(3)

            # è·å– Cookies
            cookies = self.driver.get_cookies()
            with open(self.cookie_path, "wb") as f:
                pickle.dump(cookies, f)
            print(f"ğŸ’¾ Cookie å·²ä¿å­˜è‡³ {self.cookie_path}")

            # è½¬æˆå­—ç¬¦ä¸²æ ¼å¼ä¾› requests ä½¿ç”¨
            cookie_str = "; ".join([f"{c['name']}={c['value']}" for c in cookies])
            return cookie_str

        except Exception as e:
            print(f"ğŸš¨ ç™»å½•å¤±è´¥: {e}")
            return None
        finally:
            try:
                self.driver.quit()
            except:
                pass

    def load_cookie(self) -> str:
        """ä»æœ¬åœ°åŠ è½½ Cookie"""
        if os.path.exists(self.cookie_path):
            file_time = datetime.fromtimestamp(os.path.getmtime(self.cookie_path))
            # è¶…è¿‡ 12 å°æ—¶è®¤ä¸ºè¿‡æœŸ
            if (datetime.now() - file_time).total_seconds() > 12 * 3600:
                print("ğŸ•’ Cookie å·²è¿‡æœŸï¼Œå°†é‡æ–°ç™»å½•")
                return None

            with open(self.cookie_path, "rb") as f:
                cookies = pickle.load(f)
            print("ğŸª å·²åŠ è½½æœ¬åœ° Cookie")
            return "; ".join([f"{c['name']}={c['value']}" for c in cookies])
        return None


# ================== å¾®åšçˆ¬è™«å®ç°ï¼ˆå¢å¼ºç‰ˆï¼‰==================
class WeiboCrawler:
    def __init__(self, cookie: str = None, username: str = None, password: str = None):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                          "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": "https://s.weibo.com/weibo?q=%E9%BB%84%E9%87%91%E4%BB%B7%E6%A0%BC",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "same-origin"
        })

        # è‡ªåŠ¨è·å– Cookie
        self.cookie = cookie or self._auto_login(username, password)
        if not self.cookie:
            raise ValueError("âš ï¸ æ— æ³•è·å–æœ‰æ•ˆ Cookieï¼Œè¯·æ£€æŸ¥è´¦å·å¯†ç æˆ–ç½‘ç»œç¯å¢ƒ")
        self.session.headers["Cookie"] = self.cookie
        print("ğŸª Cookie åŠ è½½æˆåŠŸ")

    def _auto_login(self, username: str, password: str) -> str:
        if not username or not password:
            raise ValueError("âŒ ç¼ºå°‘å¾®åšç”¨æˆ·åæˆ–å¯†ç ï¼Œæ— æ³•è‡ªåŠ¨ç™»å½•")

        helper = WeiboLoginHelper(username, password, "weibo_cookie.pkl")
        cookie = helper.load_cookie()
        if not cookie:
            print("ğŸ”„ å¼€å§‹è‡ªåŠ¨ç™»å½•å¾®åš...")
            cookie = helper.login()
        return cookie

    def search_posts(self, keyword: str, max_pages: int = 2) -> List[Dict[str, str]]:
        base_url = "https://s.weibo.com/weibo"
        results = []

        for page in range(1, max_pages + 1):
            params = {"q": keyword, "page": page}
            try:
                print(f"ğŸ” æ­£åœ¨è¯·æ±‚ç¬¬ {page} é¡µ: {keyword}")
                response = self.session.get(
                    base_url,
                    params=params,
                    timeout=10,
                    allow_redirects=True
                )

                if response.status_code != 200:
                    print(f"âŒ HTTP {response.status_code}: {response.text[:200]}")
                    continue

                text = response.text

                # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘æˆ–éœ€è¦éªŒè¯
                if "passport.weibo.com" in response.url or "login" in response.url:
                    raise Exception("ç™»å½•å¤±æ•ˆï¼Œè¯·æ›´æ–° Cookie")
                if "éªŒè¯" in text or "è¯·å¼€å¯ JavaScript" in text or "æ£€æŸ¥æµè§ˆå™¨" in text:
                    raise Exception("è§¦å‘åçˆ¬æœºåˆ¶ï¼Œè¯·æ›´æ¢ IP æˆ–ä½¿ç”¨ä»£ç†")

                soup = BeautifulSoup(text, "lxml")

                cards = soup.find_all("div", class_="card-wrap")
                extracted = 0

                for card in cards:
                    # è¿‡æ»¤éç”¨æˆ·å¾®åšï¼ˆå¦‚çƒ­æœæ¦œã€å¹¿å‘Šï¼‰
                    script_tag = card.find("script")
                    if script_tag and "hotsearch" in script_tag.text:
                        continue

                    user_elem = card.find("a", class_="name")
                    username = user_elem.get_text(strip=True) if user_elem else "æœªçŸ¥ç”¨æˆ·"

                    content_elem = card.find("p", class_=lambda x: x and "txt" in x)
                    if not content_elem:
                        continue
                    content = content_elem.get_text(strip=True).replace("æ”¶èµ·å…¨æ–‡", "").strip()
                    if len(content) < 5:
                        continue

                    date_elem = card.find("p", class_="from")
                    date = "æœªçŸ¥æ—¶é—´"
                    url = ""
                    if date_elem and date_elem.find("a"):
                        date = date_elem.find("a").get_text(strip=True)
                        href = date_elem.find("a").get("href")
                        url = f"https://s.weibo.com{href}" if href.startswith("/") else href

                    results.append({
                        "username": username,
                        "text": content,
                        "date": date,
                        "source": "weibo",
                        "url": url
                    })
                    extracted += 1

                print(f"âœ… ç¬¬ {page} é¡µæå–åˆ° {extracted} æ¡å¾®åš")
                time.sleep(random.uniform(2.5, 4.0))  # æ§åˆ¶é¢‘ç‡

            except Exception as e:
                print(f"ğŸš¨ çˆ¬å–å¤±è´¥: {e}")
                break  # å‡ºé”™å³åœæ­¢

        return results[:30]  # è¿”å›æœ€å¤š30æ¡


# ================== å…·ä½“èŠ‚ç‚¹å®ç° ==================
class ReceiveInputNode(WorkflowNode):
    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        print(f"ğŸ“¥ æ¥æ”¶åˆ°è¾“å…¥å…³é”®è¯: {input_data['keyword']}")
        return {"keyword": input_data["keyword"], "timestamp": datetime.now().isoformat()}


class WeiboCrawlNode(WorkflowNode):
    def __init__(self, config: NodeConfig, workflow_context):
        super().__init__(config, workflow_context)
        # ä¼˜å…ˆä½¿ç”¨èŠ‚ç‚¹å±æ€§ä¸­çš„ cookie
        self.cookie = self.attrs.get("cookie")
        self.username = self.attrs.get("username") or os.getenv("WEIBO_USERNAME")
        self.password = self.attrs.get("password") or os.getenv("WEIBO_PASSWORD")

    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        keyword = input_data.get("keyword")
        if not keyword:
            return {"success": False, "posts": [], "error": "ç¼ºå°‘å…³é”®è¯"}

        print(f"ğŸ•·ï¸ å¼€å§‹çˆ¬å–å¾®åšæ•°æ®: {keyword}")
        crawler = WeiboCrawler(
            cookie=self.cookie,
            username=self.username,
            password=self.password
        )
        posts = crawler.search_posts(keyword, max_pages=2)

        if not posts:
            return {"success": False, "posts": [], "error": f"æœªæ‰¾åˆ°å…³äº '{keyword}' çš„å¾®åšä¿¡æ¯"}

        print(f"ğŸ“Œ æˆåŠŸè·å– {len(posts)} æ¡å¾®åš")
        return {"success": True, "posts": posts}


class LLMSummarizeNode(WorkflowNode):
    def __init__(self, config: NodeConfig, workflow_context):
        super().__init__(config, workflow_context)
        self.llm_client = workflow_context["llm_client"]

    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        posts = input_data.get("posts", [])
        if not posts:
            return {"summary": "æ— å¯ç”¨å†…å®¹è¿›è¡Œæ€»ç»“"}

        texts = "\n".join([f"{p['username']}: {p['text']}" for p in posts])
        prompt_file = "./prompt/summarize_weibo.md"
        os.makedirs("./prompt", exist_ok=True)

        if not os.path.exists(prompt_file):
            with open(prompt_file, "w", encoding="utf-8") as f:
                f.write("""ä½ æ˜¯ä¸€ä¸ªèˆ†æƒ…åˆ†æä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å¾®åšå†…å®¹ï¼Œæ€»ç»“å…¬ä¼—å¯¹ã€{{keyword}}ã€‘çš„çœ‹æ³•ã€‚
è¦æ±‚ï¼š
1. åˆ†ç‚¹åˆ—å‡ºä¸»è¦è§‚ç‚¹ï¼ˆè‡³å°‘3ç‚¹ï¼‰
2. æ¯ä¸ªè§‚ç‚¹é™„ä¸Šä»£è¡¨æ€§åŸå¥ï¼ˆå¼•ç”¨ç”¨æˆ·å+å†…å®¹ï¼‰
3. æ€»ç»“æ•´ä½“æƒ…ç»ªå€¾å‘ï¼ˆä¹è§‚/æ‚²è§‚/ä¸­ç«‹ï¼‰
4. ä½¿ç”¨ä¸­æ–‡è¾“å‡º

å¾®åšå†…å®¹ï¼š
{{content}}

è¯·æŒ‰ä¸Šè¿°æ ¼å¼å›ç­”ã€‚
""")
            print(f"âœ… æç¤ºè¯æ–‡ä»¶åˆ›å»º: {prompt_file}")

        with open(prompt_file, "r", encoding="utf-8") as f:
            prompt_template = f.read()

        final_prompt = prompt_template \
            .replace("{{keyword}}", input_data.get('keyword', 'æœªçŸ¥è¯é¢˜')) \
            .replace("{{content}}", texts[:8000])  # æˆªæ–­é˜²æ­¢è¶…é™

        print("ğŸ§  æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦...")
        summary = self.llm_client.send_message(final_prompt)
        return {"summary": summary}


class FeishuNotifyNode(WorkflowNode):
    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        summary = input_data.get("summary", "æ— æ‘˜è¦å†…å®¹")
        webhook_url = self.attrs.get("webhook") or os.getenv("FEISHU_WEBHOOK")
        if not webhook_url:
            print("âŒ æœªé…ç½®é£ä¹¦ Webhookï¼Œè·³è¿‡é€šçŸ¥")
            return {"notified": False}

        msg = {
            "msg_type": "text",
            "content": {"text": f"ã€ä»Šæ—¥èˆ†æƒ…ç®€æŠ¥ã€‘\n\n{summary}\n\n---\nğŸ¤– è‡ªåŠ¨ç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M')}"}
        }
        try:
            res = requests.post(webhook_url, json=msg, timeout=5)
            if res.status_code == 200:
                print("âœ… å·²æ¨é€åˆ°é£ä¹¦")
                return {"notified": True}
            else:
                print(f"âŒ æ¨é€å¤±è´¥: {res.text}")
                return {"notified": False}
        except Exception as e:
            print(f"âŒ æ¨é€å¼‚å¸¸: {e}")
            return {"notified": False}


# ================== å·¥ä½œæµç®¡ç†å™¨ ==================
class WorkflowManager:
    def __init__(self, api_key: str, prompt_folder: str, memory_path: str):
        self.api_key = api_key
        self.prompt_folder = prompt_folder
        self.memory_path = memory_path
        self.nodes = {}
        self.workflow_context = {
            "llm_client": SimpleLLMClient(api_key),
            "memory": self.load_memory()
        }

    def register_node(self, config: NodeConfig):
        node_type = config.node_type
        if node_type == "receive_input":
            node = ReceiveInputNode(config, self.workflow_context)
        elif node_type == "weibo_crawl":
            node = WeiboCrawlNode(config, self.workflow_context)
        elif node_type == "llm_summarize":
            node = LLMSummarizeNode(config, self.workflow_context)
        elif node_type == "feishu_notify":
            node = FeishuNotifyNode(config, self.workflow_context)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„èŠ‚ç‚¹ç±»å‹: {node_type}")
        self.nodes[config.node_name] = node

    def run_workflow(self, inputs: Dict[str, Any], flow_config: List[Dict]):
        data_pool = {"input": inputs}
        last_output = None

        for step in flow_config:
            node_name = step["node_name"]
            node = self.nodes[node_name]

            # æ„å»ºè¾“å…¥
            input_data = {}
            for key, src in step["input_map"].items():
                source_node, output_key = src.split(".")
                input_data[key] = data_pool[source_node][output_key]

            # æ‰§è¡ŒèŠ‚ç‚¹
            print(f"\nğŸš€ æ‰§è¡ŒèŠ‚ç‚¹: {node_name}")
            try:
                output = node.execute(input_data)
                data_pool[node_name] = output
                last_output = output
            except Exception as e:
                print(f"âŒ æ‰§è¡Œå¤±è´¥: èŠ‚ç‚¹ {node_name} æ‰§è¡Œå¤±è´¥: {e}")
                return None

        return last_output

    def load_memory(self) -> Dict[str, Any]:
        if os.path.exists(self.memory_path):
            with open(self.memory_path, "r", encoding="utf-8") as f:
                return json.load(f)
        return {}


# ================== ç®€æ˜“ LLM å®¢æˆ·ç«¯ï¼ˆé€šä¹‰åƒé—®ï¼‰==================
class SimpleLLMClient:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.endpoint = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
        self.model = "deepseek-r1"

    def send_message(self, prompt: str, json_flag: bool = False) -> str:
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "Accept": "application/json"
        }

        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
        }

        if json_flag:
            payload["response_format"] = {"type": "json_object"}

        try:
            print("ğŸ§  æ­£åœ¨è¯·æ±‚é˜¿é‡Œäº‘ Qwen...")
            response = requests.post(
                self.endpoint,
                json=payload,
                headers=headers,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                print("âœ… LLM è¿”å›æˆåŠŸ")
                return content
            else:
                error_msg = response.text
                print(f"âŒ LLM è¯·æ±‚å¤±è´¥: {response.status_code} {error_msg}")
                return f"[LLM é”™è¯¯] {response.status_code}: {error_msg}"

        except Exception as e:
            print(f"ğŸš¨ LLM è¯·æ±‚å¼‚å¸¸: {str(e)}")
            return f"[è¯·æ±‚å¼‚å¸¸] {str(e)}"


# ================== FastAPI æ¥å£ ==================
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from contextlib import asynccontextmanager
from fastapi.middleware.cors import CORSMiddleware

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ğŸŒ å¯åŠ¨ä¸­ï¼šåˆå§‹åŒ– WorkflowManager...")
    init_workflow()
    yield
    print("ğŸ‘‹ å…³é—­ä¸­ï¼šé‡Šæ”¾èµ„æº...")

app = FastAPI(title="èˆ†æƒ…åˆ†æå·¥ä½œæµ API", version="1.0", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€ manager
manager = None

class AnalysisRequest(BaseModel):
    keyword: str

def init_workflow():
    global manager

    # ä»ç¯å¢ƒå˜é‡è¯»å–
    FEISHU_WEBHOOK = 'https://open.feishu.cn/open-apis/bot/v2/hook/77bf45ee-a658-4476-ac7e-cf3e9f538fae'
    DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
    WEIBO_USERNAME = os.getenv("WEIBO_USERNAME")
    WEIBO_PASSWORD = os.getenv("WEIBO_PASSWORD")

    if not DASHSCOPE_API_KEY:
        raise ValueError("âŒ ç¼ºå°‘ DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")

    os.makedirs("./prompt", exist_ok=True)
    os.makedirs("./workflow_memory", exist_ok=True)

    manager = WorkflowManager(
        api_key=DASHSCOPE_API_KEY,
        prompt_folder="./prompt",
        memory_path="./workflow_memory/memory.json"
    )

    nodes_config = [
        {
            "node_id": 1,
            "node_type": "receive_input",
            "node_name": "receive_01",
            "input_map": {},
            "choice_map": {"default": "weibo_crawl_01"},
            "attrs": {}
        },
        {
            "node_id": 2,
            "node_type": "weibo_crawl",
            "node_name": "weibo_crawl_01",
            "input_map": {"keyword": "receive_01.keyword"},
            "choice_map": {"default": "llm_summarize"},
            "attrs": {
                "username": WEIBO_USERNAME,
                "password": WEIBO_PASSWORD
            }
        },
        {
            "node_id": 3,
            "node_type": "llm_summarize",
            "node_name": "llm_summarize",
            "input_map": {"posts": "weibo_crawl_01.posts", "keyword": "receive_01.keyword"},
            "choice_map": {"default": "feishu_notify"},
            "attrs": {}
        },
        {
            "node_id": 4,
            "node_type": "feishu_notify",
            "node_name": "feishu_notify",
            "input_map": {"summary": "llm_summarize.summary"},
            "choice_map": {},
            "attrs": {"webhook": FEISHU_WEBHOOK}
        }
    ]

    for cfg in nodes_config:
        config = NodeConfig(**cfg)
        manager.register_node(config)

    print("âœ… å·¥ä½œæµç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")


@app.post("/analyze", summary="å¯åŠ¨èˆ†æƒ…åˆ†æ")
async def start_analysis(request: AnalysisRequest):
    if not manager:
        raise HTTPException(status_code=500, detail="å·¥ä½œæµæœªåˆå§‹åŒ–")

    print(f"ğŸŒ æ”¶åˆ°æ¥è‡ªå‰ç«¯çš„è¯·æ±‚ï¼šå…³é”®è¯ = {request.keyword}")

    flow = [
        {"node_name": "receive_01", "input_map": {"keyword": "input.keyword"}},
        {"node_name": "weibo_crawl_01", "input_map": {"keyword": "receive_01.keyword"}},
        {"node_name": "llm_summarize", "input_map": {"posts": "weibo_crawl_01.posts", "keyword": "receive_01.keyword"}},
        {"node_name": "feishu_notify", "input_map": {"summary": "llm_summarize.summary"}}
    ]

    try:
        result = manager.run_workflow({"keyword": request.keyword}, flow)
        if result and "summary" in result:
            return {
                "success": True,
                "keyword": request.keyword,
                "summary": result["summary"],
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {"success": False, "error": "åˆ†æå¤±è´¥ï¼Œæ— ç»“æœ"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/health")
async def health_check():
    return {"status": "ok", "time": datetime.now().isoformat()}