"""
LangChainé€‚é…å™¨ - å°†è‡ªå®šä¹‰w2.pyå·¥ä½œæµè½¬æ¢ä¸ºLangChainæ¶æ„
"""

from langchain_core.language_models import BaseLanguageModel
from langchain_core.prompts import PromptTemplate
from langchain.chains.base import Chain
from langchain_community.llms import QwenLLM
from langchain_core.tools import BaseTool
from langchain_core.memory import BaseMemory
from langchain.memory import ConversationBufferMemory
from typing import Dict, Any, List
import json
import os

class DailyDataAccumulator(BaseTool):
    """LangChainå·¥å…·ï¼šæ¯æ—¥æ•°æ®ç´¯ç§¯å™¨"""

    name = "data_accumulator"
    description = "ç§¯ç´¯æ¯æ—¥å¾®åšæ•°æ®ï¼Œç”¨äºå®šæ—¶åˆ†æ"

    def _run(self, keyword: str) -> str:
        # é›†æˆç°æœ‰çš„DailyDataCollectoråŠŸèƒ½
        from w2 import DailyDataCollector
        collector = DailyDataCollector()
        date_str = datetime.now().strftime("%Y%m%d")

        # è¿™é‡Œå¯ä»¥è°ƒç”¨ç°æœ‰çš„æ•°æ®ç´¯ç§¯é€»è¾‘
        return f"æ•°æ®ç´¯ç§¯å®Œæˆï¼š{keyword}"

class WeiboAnalyzerChain(Chain):
    """å¾®åšåˆ†æé“¾ - åŸºäºLangChainæ„å»º"""

    llm: BaseLanguageModel
    memory: BaseMemory
    prompt_template: PromptTemplate

    @property
    def input_keys(self) -> List[str]:
        return ["keyword", "weibo_data", "historical_context"]
    @property
    def output_keys(self) -> List[str]:
        return ["analysis_result", "push_message"]

    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        # å‡†å¤‡prompt
        context = inputs.get("historical_context", "")
        keyword = inputs["keyword"]
        weibo_data = inputs["weibo_data"]

        prompt = self.prompt_template.format(
            keyword=keyword,
            weibo_posts=weibo_data,
            context=context
        )

        # è°ƒç”¨LLM
        response = self.llm.invoke(prompt)

        # æ ¼å¼åŒ–è¾“å‡º
        result = {
            "analysis_result": response.content,
            "push_message": f"ã€ä»Šæ—¥å…³æ³¨ç‚¹ç®€æŠ¥ã€‘\n\n{response.content}\n\n---\nğŸ¤– AIåˆ†ææ¨é€"
        }

        # æ›´æ–°è®°å¿†
        self.memory.save_context(
            {"input": f"åˆ†æå…³é”®è¯ï¼š{keyword}"},
            {"output": response.content}
        )

        return result

def create_langchain_weibo_analyzer():
    """åˆ›å»ºåŸºäºLangChainçš„å¾®åšåˆ†æå™¨"""

    # LLMé…ç½® - æ›¿æ¢ç°æœ‰é˜¿é‡Œäº‘é›†æˆ
    llm = QwenLLM(
        model_name="qwen-turbo",
        api_key=os.getenv("QWQEN_API_KEY") or "sk-addb15e06fef4c19a46122a39aac8caa",
        endpoint="https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
    )

    # è®°å¿†ç³»ç»Ÿ
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )

    # æç¤ºè¯æ¨¡æ¿
    prompt_template = PromptTemplate(
        template="""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¤¾äº¤åª’ä½“åˆ†æä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä»å¾®åšè·å–çš„çœŸå®ç”¨æˆ·å‘è¨€ï¼Œå¯¹"{{ keyword }}"è¯é¢˜è¿›è¡Œæ·±å…¥åˆ†æã€‚

## åˆ†æè¦æ±‚ï¼š
1. **å†…å®¹å®šä½**ï¼šåŸºäºå‘è¨€å†…å®¹è‡ªåŠ¨åˆ¤æ–­è¿™æ˜¯ï¼ˆé‡‘è/æŠ•èµ„è¯é¢˜ï¼‰è¿˜æ˜¯ï¼ˆæ–°é—»äº‹ä»¶/ç¤¾ä¼šçƒ­ç‚¹ï¼‰ï¼Œé€‰æ‹©åˆé€‚çš„åˆ†ææ¡†æ¶

2. **æ™ºèƒ½åˆ†æ**ï¼š
   - **é‡‘èé¢†åŸŸ**ï¼ˆå¦‚è‚¡ç¥¨ã€é»„é‡‘ã€å¤–æ±‡ã€åŸºé‡‘ç­‰ï¼‰ï¼šé‡ç‚¹åˆ†æèˆ†è®ºå¯¹ä»·æ ¼èµ°åŠ¿çš„å½±å“ã€å¸‚åœºæƒ…ç»ªé¢„æµ‹ã€æŠ•èµ„å»ºè®®å€¾å‘
   - **æ–°é—»äº‹ä»¶**ï¼ˆå¦‚ç«ç¾ã€äº‹æ•…ã€æ”¿ç­–ã€ç¤¾ä¼šäº‹ä»¶ç­‰ï¼‰ï¼šé‡ç‚¹æ¢³ç†äº‹ä»¶è„‰ç»œã€ç›®å‰å‘å±•çŠ¶å†µã€å…¬ä¼—å…³æ³¨ç„¦ç‚¹

3. **è¾“å‡ºç»“æ„**ï¼š
   - ğŸ“Š **äº‹ä»¶æ¦‚è¿°**ï¼šå‘ç”Ÿäº†ä»€ä¹ˆï¼Œç›®å‰çŠ¶æ€å¦‚ä½•
   - ğŸ’­ **èˆ†è®ºæ€åº¦**ï¼šå¤§å®¶çš„æ€åº¦æ˜¯ä¹è§‚/æ‚²è§‚ï¼Œä¸­æ€§å ä¸»å¯¼å—
   - ğŸ”¥ **å…³é”®çƒ­ç‚¹**ï¼šæœ€å—å…³æ³¨çš„å‡ ä¸ªè®¨è®ºç‚¹
   - ğŸ“ˆ **è¶‹åŠ¿å±•æœ›**ï¼ˆé‡‘èè¯é¢˜ï¼‰ï¼šå¸‚åœºæˆ–ä»·æ ¼å¯èƒ½ä¼šå¦‚ä½•å‘å±•

4. **å‘ˆç°æ–¹å¼**ï¼šæ¸…æ–°æ˜“æ‡‚ï¼Œç®€æ´ä¸å•°å—ªï¼Œä¸è¶…è¿‡400å­—

**å†å²åˆ†æè®°å½•**ï¼š
{{ context }}

**å¾®åšå‘è¨€æ•°æ®**ï¼š
{% for post in weibo_posts %}
- [{{ post.username }} @ {{ post.date }}]ï¼š{{ post.text }}
{% endfor %}

ç­”æ¡ˆï¼š
""",
        input_variables=["keyword", "weibo_posts", "context"]
    )

    # åˆ›å»ºé“¾
    chain = WeiboAnalyzerChain(
        llm=llm,
        memory=memory,
        prompt_template=prompt_template
    )

    return chain

# è¿ç§»æŒ‡å—ï¼šå¦‚ä½•ä»w2.pyåˆ‡æ¢åˆ°LangChain
"""
1. æ›¿æ¢LLMè°ƒç”¨ï¼š
   - ç§»é™¤è‡ªå®šä¹‰SimpleLLMClient
   - ä½¿ç”¨LangChainçš„LLMs (å¦‚ChatOpenAI, QwenLLMç­‰)

2. å·¥ä½œæµé‡æ„ï¼š
   - w2.pyçš„WorkflowManager -> LangChain Chains/Agents
   - NodeConfig -> Chain æˆ– Tool

3. è®°å¿†ç³»ç»Ÿï¼š
   - TopicMemoryManager -> langchain.memoryæ¨¡å—

4. å·¥å…·é›†æˆï¼š
   - çˆ¬å–åŠŸèƒ½å¯ä»¥åŒ…è£…ä¸ºBaseTool
   - æ•°æ®ç´¯ç§¯å™¨ä½œä¸ºTool

5. åˆ†æé“¾ï¼š
   - ä½¿ç”¨Chainç±»æ„å»ºå®Œæ•´çš„åˆ†ææµç¨‹
   - æ”¯æŒå¤æ‚çš„promptæ¨¡æ¿å’Œè¾“å‡ºè§£æ
"""

if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    analyzer = create_langchain_weibo_analyzer()
    result = analyzer.invoke({
        "keyword": "é‡‘èå¸‚åœº",
        "weibo_data": [{"username": "ç”¨æˆ·A", "text": "å¸‚åœºèµ°åŠ¿å¾ˆå¥½", "date": "2025-12-02"}],
        "historical_context": ""
    })
    print(result)
